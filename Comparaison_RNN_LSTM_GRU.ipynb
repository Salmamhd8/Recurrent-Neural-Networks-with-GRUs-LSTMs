{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "92ed11d2-7244-4157-b373-319f018bfc13",
      "cell_type": "markdown",
      "source": "On commence par importer toutes les bibliothèques nécessaires pour le traitement et l'entraînement d'un modèle RNN/LSTM/GRU sur un jeu de données de sentiment (IMDb) :",
      "metadata": {}
    },
    {
      "id": "55978544-a0d6-479d-905e-d006d3c4944c",
      "cell_type": "code",
      "source": "import tensorflow as tf\nfrom tensorflow.keras.datasets import imdb\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Dense\nfrom tensorflow.keras.preprocessing import sequence\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline  # Pour afficher les graphs dans le notebook",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "68f7685c-db19-4b7d-90a2-35a0b51f0c34",
      "cell_type": "markdown",
      "source": "Les données IMDb sont prétraitées en limitant le vocabulaire à 5 000 mots et en ajustant chaque critique à 200 mots. Le jeu de données est chargé via imdb.load_data(), puis pad_sequences garantit une longueur uniforme des critiques ce qui est nécessaire pour l'entrée du modèle :",
      "metadata": {}
    },
    {
      "id": "8e7d9f33-00a3-4cee-b635-19590bcb0249",
      "cell_type": "code",
      "source": "max_words = 5000  # Vocabulaire limité aux 5 000 mots les plus fréquents\nmax_len = 200     # Longueur maximale des critiques\n\n(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_words)\nX_train = sequence.pad_sequences(X_train, maxlen=max_len)\nX_test = sequence.pad_sequences(X_test, maxlen=max_len)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "979f60b3-ce06-49eb-bc1d-b9ff2b702eb7",
      "cell_type": "markdown",
      "source": " Définition d'une fonction pour construire le modèle RNN/LSTM/GRU (build_model(rnn_type)). Il construit un modèle séquentiel de classification binaire basé sur le type de réseau choisi :",
      "metadata": {}
    },
    {
      "id": "5db07f83-5de3-41ba-98db-6fe9efbeb69e",
      "cell_type": "code",
      "source": "def build_model(rnn_type):\n    model = Sequential()\n    model.add(Embedding(max_words, 128))\n    \n    if rnn_type == 'simple':\n        model.add(SimpleRNN(64))\n    elif rnn_type == 'lstm':\n        model.add(LSTM(64))\n    else:\n        model.add(GRU(64))\n        \n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy',\n                 optimizer='adam',\n                 metrics=['accuracy'])\n    return model",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e92fc7c3-4f64-4732-b6d4-4f8de6b8a7fc",
      "cell_type": "markdown",
      "source": "On entraîne successivement les trois modèles : SimpleRNN, LSTM et GRU, puis on compare leurs performances :\nChaque modèle est entraîné sur le jeu de données d'entraînement pendant 5 époques avec une taille de batch de 128. Enfin, les courbes de précision de validation (val_accuracy) sont tracées pour chaque type de modèle afin de visualiser et comparer leurs performances au fil des époques :",
      "metadata": {}
    },
    {
      "id": "476ac432-ddc3-48eb-b6d8-a7b2834f9642",
      "cell_type": "code",
      "source": "plt.figure(figsize=(10, 5))\n\nfor rnn_type in ['simple', 'lstm', 'gru']:\n    model = build_model(rnn_type)\n    print(f\"\\n=== Entraînement {rnn_type.upper()} ===\")\n    history = model.fit(X_train, y_train,\n                       batch_size=128,\n                       epochs=5,\n                       validation_data=(X_test, y_test),\n                       verbose=1)\n    \n    # Sauvegarde du modèle\n    model.save(f'{rnn_type}_model.keras')\n    \n    # Courbe de performance\n    plt.plot(history.history['val_accuracy'], label=rnn_type.upper())\n\nplt.title('Comparaison des performances')\nplt.xlabel('Epochs')\nplt.ylabel('Validation Accuracy')\nplt.legend()\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2176b125-9e93-4bdd-8eb6-0dbdd66b9266",
      "cell_type": "markdown",
      "source": "=== Entraînement du modèle SIMPLE ===\n\nEpoch 1/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 29s 128ms/step - accuracy: 0.6028 - loss: 0.6465 - val_accuracy: 0.7948 - val_loss: 0.4779\n\nEpoch 2/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 21s 109ms/step - accuracy: 0.8429 - loss: 0.3674 - val_accuracy: 0.8261 - val_loss: 0.4158\n\nEpoch 3/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 21s 107ms/step - accuracy: 0.8794 - loss: 0.2941 - val_accuracy: 0.8281 - val_loss: 0.4270\n\nEpoch 4/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 27s 140ms/step - accuracy: 0.9233 - loss: 0.2060 - val_accuracy: 0.7880 - val_loss: 0.5201\n\nEpoch 5/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 23s 116ms/step - accuracy: 0.9630 - loss: 0.1093 - val_accuracy: 0.8192 - val_loss: 0.5545\n\n\n=== Entraînement du modèle LSTM ===\n\nEpoch 1/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 84s 416ms/step - accuracy: 0.6990 - loss: 0.5517 - val_accuracy: 0.8657 - val_loss: 0.3152\n\nEpoch 2/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 79s 399ms/step - accuracy: 0.8861 - loss: 0.2837 - val_accuracy: 0.8468 - val_loss: 0.3509\n\nEpoch 3/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 71s 362ms/step - accuracy: 0.9055 - loss: 0.2357 - val_accuracy: 0.8714 - val_loss: 0.3007\n\nEpoch 4/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 65s 330ms/step - accuracy: 0.9247 - loss: 0.1894 - val_accuracy: 0.8707 - val_loss: 0.3137\n\nEpoch 5/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 64s 329ms/step - accuracy: 0.9323 - loss: 0.1804 - val_accuracy: 0.8609 - val_loss: 0.3277\n\n=== Entraînement du modèle GRU ===\n\nEpoch 1/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 59s 285ms/step - accuracy: 0.6626 - loss: 0.5797 - val_accuracy: 0.8474 - val_loss: 0.3674\n\nEpoch 2/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 56s 284ms/step - accuracy: 0.8814 - loss: 0.2872 - val_accuracy: 0.8669 - val_loss: 0.3179\n\nEpoch 3/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 63s 322ms/step - accuracy: 0.9032 - loss: 0.2423 - val_accuracy: 0.8576 - val_loss: 0.3671\n\nEpoch 4/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 60s 304ms/step - accuracy: 0.9181 - loss: 0.2123 - val_accuracy: 0.8668 - val_loss: 0.3439\n\nEpoch 5/5\n\n196/196 ━━━━━━━━━━━━━━━━━━━━ 51s 258ms/step - accuracy: 0.9359 - loss: 0.1692 - val_accuracy: 0.8449 - val_loss: 0.3735\n\nLe plot généré : ![](images/myplot.png)",
      "metadata": {},
      "attachments": {}
    },
    {
      "id": "f03490ad-3df7-4531-89f0-20f1e14b9406",
      "cell_type": "markdown",
      "source": "\n",
      "metadata": {}
    },
    {
      "id": "acccda90-59b6-4ad0-86d4-13d0bc582d18",
      "cell_type": "markdown",
      "source": "Dans cette phase finale, on utilise les modèles entraînés (RNN, LSTM, GRU) pour prédire le sentiment de phrases personnalisées.\nChaque transformée en séquence numérique via le dictionnaire IMDb, puis prédite par chaque modèle.\nLe résultat indique si le sentiment est positif ou négatif, permettant de comparer les performances des architectures sur des exemples concrets :",
      "metadata": {}
    },
    {
      "id": "9376f692-b73b-4dc7-b086-6ca0a8581ec6",
      "cell_type": "code",
      "source": "word_index = imdb.get_word_index()\nreverse_word_index = {v: k for k, v in word_index.items()}\n\ndef predict_sentiment(model, text):\n    words = text.lower().split()\n    encoded = [word_index[word] for word in words if word in word_index]\n    padded = sequence.pad_sequences([encoded], maxlen=max_len)\n    pred = model.predict(padded)[0][0]\n    return \"POSITIF\" if pred > 0.5 else \"NEGATIF\", pred\n\ntest_phrases = [\n    \"This movie was a masterpiece of cinema\",\n    \"I've never seen something so terrible\",\n    \"The film had good ideas but poor execution\"\n]\n\nfor rnn_type in ['simple', 'lstm', 'gru']:\n    model = tf.keras.models.load_model(f'{rnn_type}_model.keras')\n    print(f\"\\n=== Prédictions {rnn_type.upper()} ===\")\n    for phrase in test_phrases:\n        sentiment, score = predict_sentiment(model, phrase)\n        print(f\"{phrase[:50]}... → {sentiment} ({score:.2f})\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e4cb0d0c-3416-4fbd-8405-44a6e31ff723",
      "cell_type": "markdown",
      "source": "=== Prédictions avec SIMPLE ===\n\n\"This movie was a masterpiece o...\" → POSITIF (0.99)\n\n\"I've never seen something so t...\" → POSITIF (0.86)\n\n\"The film had good ideas but po...\" → POSITIF (0.97)\n\n\n=== Prédictions avec LSTM ===\n\n\"This movie was a masterpiece o...\" → NEGATIF (0.46)\n\n\"I've never seen something so t...\" → NEGATIF (0.25)\n\n\"The film had good ideas but po...\" → POSITIF (0.63)\n\n\n=== Prédictions avec GRU ===\n\n\"This movie was a masterpiece o...\" → POSITIF (0.65)\n\n\"I've never seen something so t...\" → NEGATIF (0.35)\n\n\"The film had good ideas but po...\" → POSITIF (0.74)\n",
      "metadata": {}
    }
  ]
}